{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136b7ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "472/472 [==============================] - 1s 681us/step - loss: 0.5143\n",
      "Epoch 2/100\n",
      "472/472 [==============================] - 0s 665us/step - loss: 0.4897\n",
      "Epoch 3/100\n",
      "472/472 [==============================] - 0s 703us/step - loss: 0.4879\n",
      "Epoch 4/100\n",
      "472/472 [==============================] - 0s 682us/step - loss: 0.4869\n",
      "Epoch 5/100\n",
      "472/472 [==============================] - 0s 728us/step - loss: 0.4892\n",
      "Epoch 6/100\n",
      "472/472 [==============================] - 0s 781us/step - loss: 0.4858\n",
      "Epoch 7/100\n",
      "472/472 [==============================] - 0s 720us/step - loss: 0.4889\n",
      "Epoch 8/100\n",
      "472/472 [==============================] - 0s 775us/step - loss: 0.4908\n",
      "Epoch 9/100\n",
      "472/472 [==============================] - 0s 714us/step - loss: 0.4814\n",
      "Epoch 10/100\n",
      "472/472 [==============================] - 0s 665us/step - loss: 0.4924\n",
      "Epoch 11/100\n",
      "472/472 [==============================] - 0s 656us/step - loss: 0.4885\n",
      "Epoch 12/100\n",
      "472/472 [==============================] - 0s 656us/step - loss: 0.4887\n",
      "Epoch 13/100\n",
      "472/472 [==============================] - 0s 644us/step - loss: 0.4879\n",
      "Epoch 14/100\n",
      "472/472 [==============================] - 0s 786us/step - loss: 0.4894\n",
      "Epoch 15/100\n",
      "472/472 [==============================] - 0s 672us/step - loss: 0.4849\n",
      "Epoch 16/100\n",
      "472/472 [==============================] - 0s 650us/step - loss: 0.4919\n",
      "Epoch 17/100\n",
      "472/472 [==============================] - 0s 663us/step - loss: 0.4868\n",
      "Epoch 18/100\n",
      "472/472 [==============================] - 0s 692us/step - loss: 0.4875\n",
      "Epoch 19/100\n",
      "472/472 [==============================] - 0s 767us/step - loss: 0.4830\n",
      "Epoch 20/100\n",
      "472/472 [==============================] - 0s 659us/step - loss: 0.4913\n",
      "Epoch 21/100\n",
      "472/472 [==============================] - 0s 667us/step - loss: 0.4900\n",
      "Epoch 22/100\n",
      "472/472 [==============================] - 0s 646us/step - loss: 0.4932\n",
      "Epoch 23/100\n",
      "472/472 [==============================] - 0s 669us/step - loss: 0.4812\n",
      "Epoch 24/100\n",
      "472/472 [==============================] - 0s 656us/step - loss: 0.4920\n",
      "Epoch 25/100\n",
      "472/472 [==============================] - 0s 637us/step - loss: 0.4836\n",
      "Epoch 26/100\n",
      "472/472 [==============================] - 0s 656us/step - loss: 0.4911\n",
      "Epoch 27/100\n",
      "472/472 [==============================] - 0s 781us/step - loss: 0.4882\n",
      "Epoch 28/100\n",
      "472/472 [==============================] - 0s 646us/step - loss: 0.4854\n",
      "Epoch 29/100\n",
      "472/472 [==============================] - 0s 671us/step - loss: 0.4949\n",
      "Epoch 30/100\n",
      "472/472 [==============================] - 0s 659us/step - loss: 0.4846\n",
      "Epoch 31/100\n",
      "472/472 [==============================] - 0s 682us/step - loss: 0.4869\n",
      "Epoch 32/100\n",
      "472/472 [==============================] - 0s 741us/step - loss: 0.4905\n",
      "Epoch 33/100\n",
      "472/472 [==============================] - 0s 787us/step - loss: 0.4873\n",
      "Epoch 34/100\n",
      "472/472 [==============================] - 0s 798us/step - loss: 0.4891\n",
      "Epoch 35/100\n",
      "472/472 [==============================] - 0s 743us/step - loss: 0.4903\n",
      "Epoch 36/100\n",
      "472/472 [==============================] - 0s 767us/step - loss: 0.4855\n",
      "Epoch 37/100\n",
      "472/472 [==============================] - 0s 743us/step - loss: 0.4885\n",
      "Epoch 38/100\n",
      "472/472 [==============================] - 0s 709us/step - loss: 0.4859\n",
      "Epoch 39/100\n",
      "472/472 [==============================] - 0s 680us/step - loss: 0.4878\n",
      "Epoch 40/100\n",
      "472/472 [==============================] - 0s 724us/step - loss: 0.4901\n",
      "Epoch 41/100\n",
      "472/472 [==============================] - 0s 680us/step - loss: 0.4894\n",
      "Epoch 42/100\n",
      "472/472 [==============================] - 0s 675us/step - loss: 0.4881\n",
      "Epoch 43/100\n",
      "472/472 [==============================] - 0s 648us/step - loss: 0.4887\n",
      "Epoch 44/100\n",
      "472/472 [==============================] - 0s 673us/step - loss: 0.4895\n",
      "Epoch 45/100\n",
      "472/472 [==============================] - 0s 750us/step - loss: 0.4835\n",
      "Epoch 46/100\n",
      "472/472 [==============================] - 0s 770us/step - loss: 0.4871\n",
      "Epoch 47/100\n",
      "472/472 [==============================] - 0s 680us/step - loss: 0.4905\n",
      "Epoch 48/100\n",
      "472/472 [==============================] - 0s 709us/step - loss: 0.4916\n",
      "Epoch 49/100\n",
      "472/472 [==============================] - 0s 747us/step - loss: 0.4875\n",
      "Epoch 50/100\n",
      "472/472 [==============================] - 0s 752us/step - loss: 0.4886\n",
      "Epoch 51/100\n",
      "472/472 [==============================] - 0s 716us/step - loss: 0.4850\n",
      "Epoch 52/100\n",
      "472/472 [==============================] - 0s 752us/step - loss: 0.4887\n",
      "Epoch 53/100\n",
      "472/472 [==============================] - 1s 2ms/step - loss: 0.4894\n",
      "Epoch 54/100\n",
      "472/472 [==============================] - 0s 974us/step - loss: 0.4858\n",
      "Epoch 55/100\n",
      "472/472 [==============================] - 0s 794us/step - loss: 0.4831\n",
      "Epoch 56/100\n",
      "472/472 [==============================] - 0s 767us/step - loss: 0.4961\n",
      "Epoch 57/100\n",
      "472/472 [==============================] - 0s 745us/step - loss: 0.4844\n",
      "Epoch 58/100\n",
      "472/472 [==============================] - 0s 737us/step - loss: 0.4923\n",
      "Epoch 59/100\n",
      "472/472 [==============================] - 0s 735us/step - loss: 0.4824\n",
      "Epoch 60/100\n",
      "472/472 [==============================] - 0s 699us/step - loss: 0.4953\n",
      "Epoch 61/100\n",
      "472/472 [==============================] - 0s 709us/step - loss: 0.4808\n",
      "Epoch 62/100\n",
      "472/472 [==============================] - 0s 697us/step - loss: 0.4928\n",
      "Epoch 63/100\n",
      "472/472 [==============================] - 0s 675us/step - loss: 0.4848\n",
      "Epoch 64/100\n",
      "472/472 [==============================] - 0s 790us/step - loss: 0.4852\n",
      "Epoch 65/100\n",
      "472/472 [==============================] - 0s 697us/step - loss: 0.4935\n",
      "Epoch 66/100\n",
      "472/472 [==============================] - 1s 1ms/step - loss: 0.4874\n",
      "Epoch 67/100\n",
      "472/472 [==============================] - 0s 714us/step - loss: 0.4927\n",
      "Epoch 68/100\n",
      "472/472 [==============================] - 0s 944us/step - loss: 0.4860\n",
      "Epoch 69/100\n",
      "472/472 [==============================] - 1s 1ms/step - loss: 0.4845\n",
      "Epoch 70/100\n",
      "472/472 [==============================] - 1s 1ms/step - loss: 0.4854\n",
      "Epoch 71/100\n",
      "472/472 [==============================] - 0s 652us/step - loss: 0.4921\n",
      "Epoch 72/100\n",
      "472/472 [==============================] - 0s 648us/step - loss: 0.4900\n",
      "Epoch 73/100\n",
      "472/472 [==============================] - 0s 767us/step - loss: 0.4884\n",
      "Epoch 74/100\n",
      "472/472 [==============================] - 0s 858us/step - loss: 0.4861\n",
      "Epoch 75/100\n",
      "472/472 [==============================] - 1s 1ms/step - loss: 0.4869\n",
      "Epoch 76/100\n",
      "472/472 [==============================] - 0s 843us/step - loss: 0.4910\n",
      "Epoch 77/100\n",
      "472/472 [==============================] - 0s 743us/step - loss: 0.4889\n",
      "Epoch 78/100\n",
      "472/472 [==============================] - 1s 1ms/step - loss: 0.4853\n",
      "Epoch 79/100\n",
      "472/472 [==============================] - 1s 1ms/step - loss: 0.4913\n",
      "Epoch 80/100\n",
      "472/472 [==============================] - 0s 1ms/step - loss: 0.4811\n",
      "Epoch 81/100\n",
      "472/472 [==============================] - 0s 739us/step - loss: 0.4937\n",
      "Epoch 82/100\n",
      "472/472 [==============================] - 0s 711us/step - loss: 0.4906\n",
      "Epoch 83/100\n",
      "472/472 [==============================] - 0s 718us/step - loss: 0.4823\n",
      "Epoch 84/100\n",
      "472/472 [==============================] - 0s 667us/step - loss: 0.4884\n",
      "Epoch 85/100\n",
      "472/472 [==============================] - 0s 690us/step - loss: 0.4904\n",
      "Epoch 86/100\n",
      "472/472 [==============================] - 0s 707us/step - loss: 0.4865\n",
      "Epoch 87/100\n",
      "472/472 [==============================] - 0s 665us/step - loss: 0.4898\n",
      "Epoch 88/100\n",
      "472/472 [==============================] - 0s 684us/step - loss: 0.4914\n",
      "Epoch 89/100\n",
      "472/472 [==============================] - 0s 646us/step - loss: 0.4835\n",
      "Epoch 90/100\n",
      "472/472 [==============================] - 0s 690us/step - loss: 0.4921\n",
      "Epoch 91/100\n",
      "472/472 [==============================] - 0s 680us/step - loss: 0.4882\n",
      "Epoch 92/100\n",
      "472/472 [==============================] - 0s 745us/step - loss: 0.4869\n",
      "Epoch 93/100\n",
      "472/472 [==============================] - 0s 707us/step - loss: 0.4850\n",
      "Epoch 94/100\n",
      "472/472 [==============================] - 0s 720us/step - loss: 0.4888\n",
      "Epoch 95/100\n",
      "472/472 [==============================] - 0s 678us/step - loss: 0.4935\n",
      "Epoch 96/100\n",
      "472/472 [==============================] - 0s 733us/step - loss: 0.4819\n",
      "Epoch 97/100\n",
      "472/472 [==============================] - 0s 684us/step - loss: 0.4908\n",
      "Epoch 98/100\n",
      "472/472 [==============================] - 0s 646us/step - loss: 0.4889\n",
      "Epoch 99/100\n",
      "472/472 [==============================] - 0s 699us/step - loss: 0.4869\n",
      "Epoch 100/100\n",
      "472/472 [==============================] - 0s 642us/step - loss: 0.4839\n",
      "472/472 [==============================] - 0s 663us/step - loss: 0.4879\n",
      "202/202 [==============================] - 0s 744us/step - loss: 0.5471\n",
      "MSE Treinamento: 0.4879354238510132\n",
      "MSE Teste: 0.5470810532569885\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Carregando os dados\n",
    "address = r'C:\\Users\\Lara\\Downloads\\house_prices.csv'\n",
    "content = pd.read_csv(address)\n",
    "content.head()\n",
    "\n",
    "# Selecionando as features e os rótulos\n",
    "X = content.iloc[:, 5:6].values\n",
    "y = content.iloc[:, 2:3].values\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "scaler_x = StandardScaler()\n",
    "X = scaler_x.fit_transform(X)\n",
    "scaler_y = StandardScaler()\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "# Definindo o modelo usando Keras\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,), name='column'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Dividindo os dados em conjuntos de treinamento e teste\n",
    "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Definindo as funções de entrada\n",
    "def make_input_fn(X, y=None, num_epochs=None, shuffle=True, batch_size=32):\n",
    "    def input_function():\n",
    "        ds = tf.data.Dataset.from_tensor_slices(({'column': X}, y))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000)\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "        return ds\n",
    "    return input_function\n",
    "\n",
    "funcao_treinamento = make_input_fn(X_treinamento, y_treinamento)\n",
    "funcao_teste = make_input_fn(X_teste, y_teste, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(funcao_treinamento(), steps_per_epoch=len(X_treinamento) // 32, epochs=100)\n",
    "\n",
    "# Avaliando o modelo\n",
    "result_training = model.evaluate(funcao_treinamento(), steps=len(X_treinamento) // 32)\n",
    "result_test = model.evaluate(funcao_teste(), steps=len(X_teste) // 32)\n",
    "\n",
    "print(\"MSE Treinamento:\", result_training)\n",
    "print(\"MSE Teste:\", result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf7c3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
